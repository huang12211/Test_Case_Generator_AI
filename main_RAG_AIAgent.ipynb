{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e459cfe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install numpy\n",
    "# ! pip install pandas\n",
    "# ! pip install open-clip-torch\n",
    "# ! pip install langchain langchain-experimental\n",
    "# ! pip install langchain_chroma\n",
    "# ! pip install langchain-ollama\n",
    "# ! pip install unstructured\n",
    "# ! pip install openpyxl\n",
    "# ! pip install langchain-text-splitters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc19b451",
   "metadata": {},
   "source": [
    "# DO NOT RE-EXECUTE - Creating and Populating the Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a81dc16",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/elaine/Documents/Projects/ZB_TC_Brain_Generator/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#Create a Vector store and Identify the Embedding Model that it will use\n",
    "import os, os.path\n",
    "import shutil\n",
    "import chromadb\n",
    "from langchain_experimental.open_clip import OpenCLIPEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "import json\n",
    "import datetime\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "\n",
    "embed_model_db_path = \"./brain_DB_CLIP\"\n",
    "# embed_model_db_path = \"./brain_DB_MXBAI\"\n",
    "\n",
    "#Erase Persistent VectorStore Database\n",
    "if os.path.isfile(embed_model_db_path + \"/chroma.sqlite3\"):\n",
    "    # os.remove(\"./brain_DB/chroma.sqlite3\")\n",
    "    shutil.rmtree(embed_model_db_path)# Delete the entire directory\n",
    "\n",
    "\n",
    "chroma_client = chromadb.PersistentClient(path= embed_model_db_path)\n",
    "col_name = 'brain_gen_2_panels'\n",
    "\n",
    "#Instatiate OpenCLIP model\n",
    "match embed_model_db_path:\n",
    "    case \"./brain_DB_CLIP\":\n",
    "        emb_func = OpenCLIPEmbeddings(model_name = 'ViT-B-32', checkpoint = 'laion2b_e16') #Multimodal Embedding LLM\n",
    "    case \"./brain_DB_MXBAI\":\n",
    "        emb_func = OllamaEmbeddings(model = 'mxbai-embed-large', temperature = 0) #recommended by Ollama for embedding textual data\n",
    "\n",
    "#Create the Vector store using Chroma\n",
    "vectorstore = Chroma(collection_name = col_name,\n",
    "                     embedding_function = emb_func,\n",
    "                     client = chroma_client)\n",
    "\n",
    "collection = chroma_client.get_or_create_collection(name = col_name)\n",
    "\n",
    "#Check if the collection was created in the Chroma DB Client\n",
    "def check_collection_exists():\n",
    "    try:\n",
    "        collection = chroma_client.get_collection(name = col_name)\n",
    "        print(f\"Collection '{col_name}' exists.\")\n",
    "        return True\n",
    "\n",
    "    except ValueError:\n",
    "        print(f\"Collection '{col_name}' does not exist.\")\n",
    "        return False\n",
    "\n",
    "# check_collection_exists()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8dde2b5",
   "metadata": {},
   "source": [
    "## Add SWRS to the Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "979ecca9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3f3fd603-64b3-43e0-adff-02a472037d72',\n",
       " 'd80899f4-d8c6-45c0-8bd4-23ee7d4492e3',\n",
       " 'ef767fb5-ad60-4264-8006-b268a9757320',\n",
       " 'bfa7fc47-993b-44af-b7d2-f258e0fa4924',\n",
       " '99a2423a-d693-4b60-946e-56f6dc95f477',\n",
       " '3d991a1f-72d2-48e3-bf6b-a7db8f6ce17e',\n",
       " 'b9c2c21d-81b1-4210-8bcb-3ec9ac4a4d35',\n",
       " '2b7112bf-dbf8-4ae6-a812-32adda9c6780',\n",
       " 'fd8d785f-f98f-4091-b183-418f15e7f052',\n",
       " 'ab6c0cc9-5826-4366-9f56-778c64b764ff',\n",
       " 'fecf5415-38de-4701-9988-c656d40b6ef4',\n",
       " 'a9c8b89f-e848-48c7-8922-ba8508b428fe',\n",
       " '48cb93a5-5897-4ac1-a544-aec2d3b10759',\n",
       " 'f10d0ff6-b834-4997-8d9e-a640ce785441',\n",
       " '7cd4e8ad-0311-4bff-ae43-6f1c9c7ad224',\n",
       " '620c4870-e32e-4fbf-a883-53d022d4f533',\n",
       " '4c5e25d4-f502-48d8-ba77-9f4a1e5f40a7',\n",
       " '6c257a9b-6cae-47ad-81b3-f90e32a09b1f',\n",
       " '4ba107a2-c5ca-407f-a884-6b8a2feb9a99',\n",
       " '4189dca6-b3d2-4116-9a42-19385d9ce0d7',\n",
       " 'e5cecdae-fc03-4713-bbc8-0e1bdd033f37',\n",
       " '5131c0f7-9620-4976-a76b-166c249a73b2',\n",
       " '4b095478-bf68-4b40-950c-9823cd4cd09d',\n",
       " 'e8245f38-beb7-4b1d-8ded-28181163c014',\n",
       " 'be0d0169-7634-4747-888c-8efd84f68a13',\n",
       " 'a848304d-1454-449d-913b-16ad44957208',\n",
       " '8195f5aa-b8f5-4927-8706-30c79c937401',\n",
       " 'a1c6e5e6-d668-4116-a70b-b3604d68fc32',\n",
       " '955e077b-5c84-4ea8-b339-7245620049b6',\n",
       " '037f6ca0-f551-49f9-986f-531c78b5804a',\n",
       " '990a9619-1a54-4037-a86e-a3b5e530e421',\n",
       " '4175f9f3-8372-4654-99fe-6541d3342ade',\n",
       " 'd6fe8140-d3a1-47f8-b2e8-44eb633358d2',\n",
       " '27d2d7bf-9037-48da-a861-ef0c42700130',\n",
       " 'e911e49e-dd66-4989-907f-c72fb66d5dc3',\n",
       " '224bed45-32d9-4a52-8c37-8591cf5a72b4',\n",
       " 'beb8b60e-cb83-4ba8-b15a-ce1516de580b',\n",
       " '1e845225-cff4-4d78-83ae-8511abfebdee',\n",
       " '5843f2e2-f6e8-4e4c-8aac-c5e79d9c1829',\n",
       " '8c829227-f4cb-4ac1-b1d0-2ceb8aab5005',\n",
       " '99378b91-bc93-4b36-8bc6-2cde6d3a1163',\n",
       " '9fd481bf-bf4c-4219-9f7a-86b33db38457',\n",
       " '246eb876-0004-4049-bbf9-dbda430472a4',\n",
       " '416fd739-b2d2-4f21-9546-406a88dd577b',\n",
       " '9bf09481-03db-41a8-a4a7-5e8ce4ea5f9b',\n",
       " '80ebc22d-e78c-4a8e-baee-a775f3b6ba70',\n",
       " 'd9a86291-2a30-4b71-bba4-e6fd190b12ee',\n",
       " '0cd5b215-52b8-48da-8d96-fefc50ea8bd2',\n",
       " '02f609ee-b1b8-48bf-ad4a-e6ebcdbdb997',\n",
       " '1eaac1a6-a4db-470a-9e26-49234dc6cb85',\n",
       " 'adc67252-95b7-48f6-9636-0a016f0a570f',\n",
       " 'd880b6b7-428f-4ff5-8125-8dbb41fd89f8',\n",
       " '7492590c-eb1c-402d-8593-d6f3600d4466',\n",
       " 'e69fb3d9-751a-424e-9e60-8231f347673d',\n",
       " '7d3d78cc-6864-450f-902d-e40f80daad53',\n",
       " '99655104-eb72-4cb2-9e48-8c572dc201a5',\n",
       " '26b176df-948b-4ef0-8146-19d29509fa8c',\n",
       " 'e45ecc87-cf5d-462a-a85c-447302b9aedc',\n",
       " '06377f47-701d-4481-aa45-ab9a083a4bfc',\n",
       " '68609d9e-e07f-4538-aa1d-6e3dac725ba8',\n",
       " 'd93de485-1120-4247-93b6-48531215a9d6',\n",
       " 'cae1f19a-de3e-4f11-b626-b9abc4ca9efd',\n",
       " '8ea41980-fdb7-4c2b-988e-c3c5f3f2a75b',\n",
       " '416dd14e-7ea6-4664-acca-2ed24db9c4f3',\n",
       " '4a2f15f9-5feb-48e5-a2c6-7ab0982bf69e',\n",
       " 'c87eb62d-9107-4026-ae67-903fbdf5f933',\n",
       " '601ae364-1fbf-449c-b659-f1c757100c54',\n",
       " 'e944f0d2-215c-42b7-90e3-37ca55e8591e',\n",
       " 'c7c09bf5-2185-4bfa-844e-cc7a9ba2bc0b',\n",
       " 'c65f1988-e7e6-4c6c-ae99-027be465a193',\n",
       " 'fb695eb6-fee1-4db8-a4e0-e337e9a30ba2',\n",
       " '0f43a9e8-9eee-4fa4-95ad-dd23a182dee0',\n",
       " '59210150-20ff-4940-9be3-ffc5d4d4f595',\n",
       " 'f7a5b70b-28a5-4bb1-8754-9240a707d890',\n",
       " 'aead717c-7fc7-4b1a-9269-8abd92d81738',\n",
       " '4b96af90-baac-456e-97d6-30bc90109d18',\n",
       " '83ad5077-c14d-44fb-a44a-675a7e5b023a',\n",
       " 'a9c3f733-87c0-4774-9f3d-77f4675feefb',\n",
       " '93056a87-9650-4de3-ba13-8ade52d4526e',\n",
       " '89d5d240-2e66-4c3e-8489-7c0533fd492c',\n",
       " '9015c09e-fd7b-49bc-beca-bb2cfafb17e7',\n",
       " '48c1f657-f4ec-4efc-8d30-ee1283c2d996',\n",
       " '43bd35ce-7f31-4d00-a3bb-eb0d9e2504de',\n",
       " 'd7f3ad72-7402-46ba-a025-0e41ea3116da',\n",
       " 'a337e88f-c119-45c7-9330-9ec16b9b5879',\n",
       " '2c3c6df3-709e-4c94-90b5-d8f0ae4d6c0c',\n",
       " '9d67241e-0550-4b66-b93d-fe619e503dfa',\n",
       " 'd649f625-86f5-4bff-a822-5c1b4d84afdc',\n",
       " '47794632-271e-4cef-bf26-0b2f53205f76',\n",
       " '97aa2dce-b68c-43c4-a9c8-8bfd52e265ab',\n",
       " '09cfb01e-314f-478f-87c6-4c4443ea1876',\n",
       " '1740d7c3-bed8-40eb-9ed9-16d34cf778b8',\n",
       " '24b84cd1-cd8f-4bb4-a76d-f0ca76ba5224',\n",
       " '94f122fc-2889-4f75-b06c-effbd16e1f5b',\n",
       " '228cf301-56aa-4a3f-a49f-f31f3478a946',\n",
       " '85d5d16f-2021-42c9-81ba-1ffb2eefbf22',\n",
       " '795e6f16-4ae2-4ca6-b941-1ed3c414b3c0',\n",
       " 'bd1bf803-f117-4849-9aae-17fd2bdbf9bd',\n",
       " '29f1a493-9c90-4dca-8f5e-8d6cd86cc68b',\n",
       " '0bf5010e-90dd-4752-9bdc-ef3714005ed9',\n",
       " 'b1153e8e-addc-4de6-a54e-1a9daff585c2',\n",
       " '6d97c415-39a6-46d6-a2c2-0d26565901d0',\n",
       " 'e3a899d0-40f1-40aa-ad8c-ec939e1d96d5',\n",
       " '1f0b2277-382f-49e2-b425-1829389f7c19',\n",
       " '8f02f109-14d7-4ef9-845f-ad3a7775a6d1',\n",
       " '123dad6d-63cc-4240-a3f8-32d2b9b514dd',\n",
       " '558df401-26b3-46b8-93f6-14c6b06f6b9c',\n",
       " '677daf70-6b75-43a1-9396-8aae92df6e42',\n",
       " '60efe950-431d-4175-a721-73a9481fa8ce',\n",
       " 'a5b121ea-f1f9-49cf-9c04-d43adc9643dd',\n",
       " 'a5acbdeb-5fce-4398-a3a6-8854defeb26e',\n",
       " '5119cd38-1b30-40c4-b6f9-4fa46429487c',\n",
       " 'c5e0ee0b-a01b-44a0-9f82-f32e81cdb492',\n",
       " '827c3e2f-1fda-446c-9182-8497dbcaeba9',\n",
       " 'a1243c26-54ce-4ad5-88cc-70c14517153d',\n",
       " '8d71420a-a33d-4582-bf24-0575932b37a6',\n",
       " '7a562fed-6f02-4335-b6df-c851b63068dc',\n",
       " 'b93451d7-16f9-4613-b69c-e9748b357a57',\n",
       " '46863bb2-1bcd-4bb2-9584-083746f1bfce',\n",
       " '29fa5e9b-1c66-46dd-939f-ea00d1eb296a',\n",
       " 'a73b5f1b-aa7b-4018-9b25-fcf9d281d37e',\n",
       " 'f8b935a8-c763-46c4-a1ae-8b0ab536ad35',\n",
       " '707673b5-a0c9-4d9d-b9d3-ff7e007bdaeb',\n",
       " '3aebb434-fada-49aa-b42e-88d8f71b5136',\n",
       " 'd872dbc7-74d6-4b43-8b15-d920ec357cec',\n",
       " '4735c93b-9c27-4504-9a9e-e472f1fb3bff',\n",
       " '7e43b456-d406-4ee1-b440-a22952542eb7',\n",
       " '092019f6-bd6e-4112-b40b-82f9a92d8df5',\n",
       " 'd5261d01-6ff4-403e-bb85-d6e631a093b4',\n",
       " '135521dd-6646-4a68-8f35-e0d2fb9dcb72',\n",
       " '69b8c33e-49c7-4aaf-a2b2-7e2b89a3bf4e',\n",
       " '045aa143-5beb-43b2-ace5-146af831c6c7',\n",
       " '0ce697bb-0c3c-4644-851f-ec99078ffdcd',\n",
       " 'b7a983aa-74b0-4bd2-9e06-7a7e002de8fd',\n",
       " '3c9a0f40-d532-4a81-87d7-65694fa12b7a',\n",
       " '9b2b12a4-a2bf-4d8a-9729-3cc827d710a1',\n",
       " 'fbd5ea07-56ad-49aa-97c0-aee71da02ca2',\n",
       " '1c92c692-147c-4813-9f16-7e60c5a4424c',\n",
       " 'e8bcd0a3-574f-44aa-b85e-c1800213cf3e',\n",
       " '6c501f89-470d-4381-a567-a57a596b37f6',\n",
       " '9fb4f370-115e-4cab-807a-62741fb5b078',\n",
       " 'be6e9a4a-4574-404e-820d-3f54f2e19506',\n",
       " 'af5bd829-9930-43e9-8e67-b3dc344264ea',\n",
       " '3bb35ef6-cb80-4e82-9e42-77b1e444d2a1',\n",
       " 'a7011cb6-91f0-4736-9b2d-a3751400b1ba',\n",
       " 'da71f993-d411-491c-9061-a175fe2d9891',\n",
       " '091d6fff-f241-4116-822d-b35841705d7f',\n",
       " '8e81dd76-e5be-4e05-8e37-29f55333cc2c',\n",
       " '80bce04f-229f-48b6-a4da-8431bf43b3bc',\n",
       " 'b13b26dc-2671-40e9-af9e-e5ec019fc29c',\n",
       " '91001de0-c3e0-4b74-8547-b05c067b1304',\n",
       " '5c72caf5-afcd-4477-9bc0-b052eba60e07',\n",
       " '61c2779e-6624-402c-8b24-d8fe87791bff',\n",
       " 'e9fab6ad-712d-4280-8cf7-306e1b27d8ae',\n",
       " '06bc3bca-62fe-43fc-a276-99ab34853678',\n",
       " 'c290399b-2fd8-49ff-a38a-65c113cc1ead',\n",
       " '7771fa37-3609-4897-889d-088d32a1b181',\n",
       " '30f5a0f9-4d6a-4daf-b173-bce3d4eac5fc',\n",
       " '370946af-21f8-42f7-89bc-879ced8a27c5',\n",
       " 'e511c2df-8e6a-4145-a74c-ad58e7cd84fe',\n",
       " '5cbcc75f-0e38-4a8e-b576-769f7b511c12',\n",
       " '362dcf93-4478-49ce-bcb8-acd65af321f2',\n",
       " 'f29373a0-d9ab-46c0-a937-8111817f0253',\n",
       " '44fb5d84-5980-4d7b-8553-4c86a556507b',\n",
       " 'f9d89df1-6eed-43ac-9f19-c78689a3229e',\n",
       " 'f1862942-df2c-4d77-b88f-74288750b31d',\n",
       " '864607c9-b127-4f2b-93b8-7533b8b9f856',\n",
       " '65adae6f-d437-4f85-b816-1cbcbb8b1d12',\n",
       " 'e2ec8468-0e4a-4ee3-80c1-44c53df16a70',\n",
       " '989b4479-b8e4-4b58-8129-2e3daa0ededf',\n",
       " '551eabef-9db4-4577-9405-cc9f7f1b48b6',\n",
       " 'b782f3e6-2090-4841-8a0c-94b5517267eb',\n",
       " '3c7ec1e6-fd4e-4539-9e44-369e32febf5d',\n",
       " 'df695d94-698f-4daf-8697-0a971319e163',\n",
       " 'f34e8b63-e323-468c-a7a3-bc7175e40806',\n",
       " '6ce43907-0648-4f2e-be8f-e1a2e13b0b8a',\n",
       " 'ca498f19-d058-4647-9582-76daa8ef4f9d',\n",
       " 'e44952cf-1a7a-4321-b613-a92a4672c2c9',\n",
       " '8807c276-debe-45dd-b843-c48dfce09b19',\n",
       " '25be8871-25b8-49a2-9172-b17f318e4d73',\n",
       " 'f3881e71-d55c-4c52-8723-ec92befc14cf',\n",
       " 'f2c1dcb9-a111-445c-82d0-e032c0b931f9',\n",
       " '35c3652d-c98d-4aab-b229-977153e3f864',\n",
       " '8c52e599-95b6-4456-9fa2-a61fb2853318',\n",
       " '75463646-b000-480f-b468-745ca4cacd78',\n",
       " 'cb9e6382-de13-437f-816c-6feb05e374cd',\n",
       " '71d6d68f-73aa-4ba7-849e-71aaaf3e3f85',\n",
       " '79cd2a29-4cdf-41b7-b7df-59f5b50440c0',\n",
       " '79a1d5e1-c6c1-4b6c-8686-1f9d8373ecf3',\n",
       " '6560efe0-42cb-4e9c-86a6-5bf9e65be068',\n",
       " '280ae5fd-fd0c-4b76-964a-1f27a4ec6d53',\n",
       " 'a51a7556-dac9-46fd-8c42-4c8a71c87ebc',\n",
       " '6377f7f6-d067-4d1e-9e15-6a97b098895d',\n",
       " '3ebdaea0-8a57-4360-ae5e-8bff7b3f3d36',\n",
       " '27b33ed5-862d-4288-bb67-9fa1a11159b5',\n",
       " '59ff0e5c-99d7-4156-bdab-d8ca1db78360',\n",
       " '5333550f-2a03-467c-8f3e-3c6b32db88ea',\n",
       " 'd50ddcd1-472f-4a85-be6e-cd31d16dba3e',\n",
       " '55f5f722-8700-4679-9b84-aaf3178dad1b',\n",
       " '6880fbce-e37b-4cd0-ae0c-4f4313521089',\n",
       " 'c11e4b7e-0f5f-4178-9721-e3a2c43e90ba',\n",
       " '632e158c-ebf2-45eb-b142-f7bb0f6ce9a6',\n",
       " 'a6f9f695-b826-44c7-a649-7d820fbab12c',\n",
       " '5b8b576d-82f5-4aec-85ca-aa9e08b9dd2d',\n",
       " 'd2c45bda-296d-4520-925e-4f87bf492402',\n",
       " '18609111-0d02-462d-aefa-95358316b747',\n",
       " 'a5c00a4d-56a1-4550-8f95-5cc5b8ba00d7',\n",
       " '3afac76b-861f-4a45-8c19-99c071d4b7eb']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import all of the SWRS after chunking it up.\n",
    "from langchain_community.document_loaders import UnstructuredExcelLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "loader = UnstructuredExcelLoader(\"./inputs/swrs/SWRS-BrainGENII.xlsx\")\n",
    "docs = loader.load()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, \n",
    "                                               chunk_overlap=100, \n",
    "                                               is_separator_regex= True,\n",
    "                                               separators=[r\"\\b\\d{6,8}\\b\"], \n",
    "                                               add_start_index = True)\n",
    "\n",
    "# the following text splitters performed worse than the OG:(1000, 200), (500, 200) \n",
    "# the following performed the same as the OG: (600, 100)\n",
    "# text_splitter = RecursiveCharacterTextSplitter(chunk_size=600, \n",
    "#                                                chunk_overlap=100, \n",
    "#                                                is_separator_regex= True,\n",
    "#                                                separators=[r\"\\b\\d{6,8}\\b\"], \n",
    "#                                                add_start_index = True)\n",
    "\n",
    "######################################################\n",
    "# TODO: Check if Semantic Chunking would work better #\n",
    "######################################################\n",
    "\n",
    "chunked_docs = text_splitter.split_documents(docs)\n",
    "\n",
    "# print(chunked_docs[1])\n",
    "\n",
    "vectorstore.add_documents(documents = chunked_docs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f9003c",
   "metadata": {},
   "source": [
    "## Add the JSON files that contain descriptions of all UI components in each panel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "abf447d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----CONTEXT VECTORSTORE CREATED------\n"
     ]
    }
   ],
   "source": [
    "# import all of the json files describing each the components contained in each panel in the application\n",
    "\n",
    "path_json_folder = './inputs/json'\n",
    "json_filenames = os.listdir(path_json_folder)\n",
    "\n",
    "all_json_paths = []\n",
    "for i in range(len(json_filenames)):\n",
    "    all_json_paths.append(f'{path_json_folder}/{json_filenames[i]}')\n",
    "\n",
    "\n",
    "all_json_contents = []\n",
    "all_json_metadata = []\n",
    "\n",
    "for path in all_json_paths:\n",
    "    content = open(path).read().strip()\n",
    "    all_json_contents.append(content)\n",
    "    all_json_metadata.append({\"source\": path})\n",
    "\n",
    "#Add the json files to the vector store\n",
    "vectorstore.add_texts(texts = all_json_contents,\n",
    "                      metadatas = all_json_metadata)\n",
    "\n",
    "print(\"----CONTEXT VECTORSTORE CREATED------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e19bcc40",
   "metadata": {},
   "source": [
    "# Reaccess Persistent VectorStore that Already Exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f677cb92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, os.path\n",
    "import chromadb\n",
    "from langchain_experimental.open_clip import OpenCLIPEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "import datetime\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "\n",
    "chosen_emb_model = \"CLIP\"\n",
    "# chosen_emb_model = \"MXBAI\"\n",
    "\n",
    "match chosen_emb_model:\n",
    "    case \"CLIP\":\n",
    "        dir = \"./brain_DB_CLIP\"\n",
    "        emb_func = OpenCLIPEmbeddings(model_name = 'ViT-B-32', checkpoint = 'laion2b_e16') #Multimodal Embedding LLM\n",
    "    case \"MXBAI\":\n",
    "        dir = \"./brain_DB_MXBAI\"\n",
    "        emb_func = OllamaEmbeddings(model = 'mxbai-embed-large', temperature = 0) #recommended by Ollama for embedding textual data\n",
    "\n",
    "col_name = 'brain_gen_2_panels'\n",
    "vectorstore = Chroma(persist_directory = dir, \n",
    "                     embedding_function = emb_func,\n",
    "                     collection_name = col_name)\n",
    "retriever = vectorstore.as_retriever()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd5aa1da",
   "metadata": {},
   "source": [
    "# Nodes Outside of Graph\n",
    "\n",
    "https://github.com/langchain-ai/langgraph/blob/main/examples/rag/langgraph_self_rag.ipynb?ref=blog.langchain.com \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a06143",
   "metadata": {},
   "source": [
    "## Compile list of Models you want to test when Infering Answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d5a95aa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llama3.1-8b\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_ollama.chat_models import ChatOllama\n",
    "# Models that fail to run the full graph:\n",
    "#################################\n",
    "# model_llava = ChatOllama(model=\"llava:7b\", temperature = 0) \n",
    "\n",
    "#Models that successfully run the full graph:\n",
    "#################################\n",
    "model_gemma = ChatOllama(model = \"gemma3:4b\", temperature = 0)\n",
    "model_llama = ChatOllama(model = 'llama3.1:8b', temperature = 0)\n",
    "model_granite = ChatOllama(model = 'granite3.2:8b', temperature = 0)\n",
    "\n",
    "\n",
    "def get_current_model (sel_model):\n",
    "    match sel_model.model:\n",
    "        case ('gemma3:4b'):\n",
    "            return 'gemma3-4b'\n",
    "        case ('llama3.1:8b'):\n",
    "            return 'llama3.1-8b'\n",
    "        case ('granite3.2:8b'):\n",
    "            return ('granite3.2-8b')\n",
    "        \n",
    "sel_model = model_llama\n",
    "model_name = get_current_model(sel_model)\n",
    "print(model_name)\n",
    "\n",
    "\n",
    "#Have a way to separate if data is coming from image source or text source\n",
    "import base64\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "\n",
    "def decode_base64_image(base64_string):\n",
    "    \"\"\"Decode a Base64 string into a PIL.Image.Image object.\"\"\"\n",
    "    image_data = base64.b64decode(base64_string)\n",
    "    return Image.open(BytesIO(image_data))\n",
    "\n",
    "\n",
    "def is_base64(s):\n",
    "    \"\"\"Check if a string is Base64 encoded\"\"\"\n",
    "    try:\n",
    "        return base64.b64encode(base64.b64decode(s)) == s.encode()\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "def reshape_results(docs):\n",
    "    images = []\n",
    "    text = []\n",
    "    for doc in docs:\n",
    "        doc = doc.page_content  # Extract Document contents\n",
    "        if is_base64(doc):\n",
    "            images.append(\n",
    "                decode_base64_image(doc)\n",
    "            )  # base64 encoded str\n",
    "        else:\n",
    "            text.append(doc)\n",
    "    return {\"images\": images, \"texts\": text}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da6a4351",
   "metadata": {},
   "source": [
    "## Grader of Retrieved Documents: Create LLM that checks the relevance of the retrieved documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "70209ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "\n",
    "# Data model\n",
    "class GradeDocuments(BaseModel):\n",
    "    \"\"\"Binary score for relevance check on retrieved documents.\"\"\"\n",
    "\n",
    "    binary_score: str = Field(\n",
    "        description=\"Documents are relevant to the question, 'yes' or 'no'\"\n",
    "    )\n",
    "\n",
    "\n",
    "# LLM with function call\n",
    "structured_llm_grader = sel_model.with_structured_output(GradeDocuments)\n",
    "\n",
    "# Prompt\n",
    "system1 = \"\"\"You are a grader assessing relevance of a retrieved document to a user question. \\n \n",
    "    It does not need to be a stringent test. The goal is to filter out erroneous retrievals. \\n\n",
    "    If the document contains keyword(s) or semantic meaning related to the user question, grade it as relevant. \\n\n",
    "    Give a binary score 'yes' or 'no' score to indicate whether the document is relevant to the question.\"\"\"\n",
    "\n",
    "system2 = \"\"\"You are an expert evaluator. Given a user query and a retrieved document, your task is to assess whether the document is relevant to the query.\n",
    "First, return one of the following labels:\n",
    "- RELEVANT – if the document directly answers or provides significant, useful information related to the query.\n",
    "- PARTIALLY_RELEVANT – if the document touches on the topic but does not fully address the query or only covers part of it.\n",
    "- IRRELEVANT – if the document does not answer the query or is off-topic.\n",
    "If the label is \"RELEVANT\" OR \"PARTIALLY_RELEVANT\" then give a score of \"yes\".\n",
    "If the label is \"IRRELEVANT, then give a score of \"no\".\n",
    "\"\"\"\n",
    "\n",
    "system3 = \"\"\"You are a grader assessing the relevance of a retrieved document to a user question.\n",
    "If the document contains keyword(s) or semantic meaning related to the user question, grade it as relevant. \n",
    "If the document touches on the topic but does not fully address the question or only covers part of it, grade it as relevant.\n",
    "If the document contains no relevant information, grade it as irrelevant. \n",
    "Give a binary score 'yes' or 'no' score to indicate whether the document is relevant to the question.\n",
    "\"\"\"\n",
    "\n",
    "ret_system_prompt = system1\n",
    "grade_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", ret_system_prompt),\n",
    "        (\"human\", \"Retrieved document: \\n\\n {document} \\n\\n User question: {question}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "retrieval_grader = grade_prompt | structured_llm_grader\n",
    "\n",
    "# Uncomment to troubleshoot if Grader of Retrieved documents works without bugs: \n",
    "# question = \"agent memory\"\n",
    "# docs = retriever.get_relevant_documents(question)\n",
    "# doc_txt = docs[1].page_content\n",
    "# print(retrieval_grader.invoke({\"question\": question, \"document\": doc_txt}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e805e3e",
   "metadata": {},
   "source": [
    "## Test Case Generator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ef1d03",
   "metadata": {},
   "source": [
    "### Preprocessing Golden TC Examples\n",
    "\n",
    "Examples of your desired output should only be fed as part of your prompt. You can do this by passing these examples as variables to the prompt. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cfc94ee7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./inputs/example_tcs/TC - MKR002 - Setup Breadcrumb Step - Navigation Buttons Flow - Arm is Home (1+ Pointer .json file).md\n",
      "./inputs/example_tcs/TC - MKR003 - From Select SN Subpanel to Install Pointer Subpanel (1+ Pointer .json file).md\n",
      "./inputs/example_tcs/TC - MKR001 - Setup Breadcrumb Step - Navigation Flow - Arm is Home (1+ Pointer .json file).md\n",
      "./inputs/example_tcs/TC - MKR004 - Install Pointer Subpanel - Change SN button (1+ Pointer .json file).md\n",
      "./inputs/example_tcs/TC - ICT - Image Acquisition Breadcrumb Step - Forward Flow - Check Content.md\n",
      "./inputs/example_tcs/TC - ICT - Enter Setup Breadcrumb Step - Forward Flow - Arm is Home (1+ Object .json files).md\n",
      "./inputs/example_tcs/TC - ICT - Return to Setup Breadcrumb Step - Arm Not Home - Flow up to Select Object SN Subpanel (1+ Object .json file).md\n",
      "./inputs/example_tcs/TC - MKR005 - From Install Pointer Subpanel to Move to Working - Successful Verification.md\n"
     ]
    }
   ],
   "source": [
    "#import all markdown files that are golden examples of test cases\n",
    "path_tc_folder = './inputs/example_tcs'\n",
    "tc_filenames = os.listdir(path_tc_folder)\n",
    "\n",
    "all_tc_paths = []\n",
    "for i in range(len(tc_filenames)):\n",
    "    if (not tc_filenames[i].startswith(\".\")):\n",
    "        all_tc_paths.append(f'{path_tc_folder}/{tc_filenames[i]}')\n",
    "\n",
    "all_tc_contents = []\n",
    "all_tc_metadata = []\n",
    "\n",
    "for path in all_tc_paths:\n",
    "    print(path)\n",
    "    content = open(path).read().strip()\n",
    "    all_tc_contents.append(content)\n",
    "    all_tc_metadata.append({\"source\": path})\n",
    "\n",
    "#Add the json files to the vector store\n",
    "# vectorstore.add_texts(texts = all_tc_contents,\n",
    "#                       metadatas = all_tc_metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb7d406",
   "metadata": {},
   "source": [
    "### Generate Prompt Templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "691dbf73",
   "metadata": {},
   "outputs": [],
   "source": [
    "template_ex_TC_from_file = \"\"\"\n",
    "<INSTRUCTIONS>\n",
    "You are a test engineer that generates test cases. \n",
    "For each test case, provide a brief description of the test case and the test steps.\n",
    "Every test step must have an expected result of what should be displayed on the screen.\n",
    "Do not use personal pronouns in the test case. \n",
    "The results of a search of a database of screenshots of the application have been provided to give you more context. \n",
    "Use the information in the results to help you generate test cases for the specified features accurately.\n",
    "Not all information in the results will be useful. \n",
    "Write as many test cases as needed to completely verify the test case objectives. \n",
    "However, if you find any information that's useful for generating a test case for the feature specified by the user, draw from it in your answer. \n",
    "<EXAMPLE> {example1} </EXAMPLE>\n",
    "<EXAMPLE> {example2} </EXAMPLE>\n",
    "<EXAMPLE> {example3} </EXAMPLE>\n",
    "</INSTRUCTIONS>\n",
    "\n",
    "<FEATURE> {feature} </FEATURE>\n",
    "\n",
    "<RESULTS> {context} </RESULTS>\n",
    "\n",
    "ANSWER:\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "template = template_ex_TC_from_file\n",
    "\n",
    "def gen_TC_w_ex_from_files(feature, context, model = sel_model):\n",
    "    global template\n",
    "    template = template_ex_TC_from_file\n",
    "    prompt = ChatPromptTemplate.from_template(template)\n",
    "    chain = prompt | model\n",
    "\n",
    "    example1 = all_tc_contents[0]\n",
    "    example2 = all_tc_contents[1]\n",
    "    example4 = all_tc_contents[3]\n",
    "    example5 = all_tc_contents[4]\n",
    "    example6 = all_tc_contents[5]\n",
    "    example7 = all_tc_contents[6]\n",
    "    example8 = all_tc_contents[7]\n",
    "    \n",
    "    return chain.invoke({\"example1\": example1, \"example2\": example2, \"example3\": example4,\n",
    "                         \"feature\": feature, \"context\": context})\n",
    "\n",
    "numb_ret = 10\n",
    "output_path = './outputs/'\n",
    "def output_TC(feature, retrieved_info, answer, iter):\n",
    "    global numb_ret\n",
    "    global ret_system_prompt\n",
    "    global logtime\n",
    "    model_name = get_current_model(sel_model)\n",
    "    # logtime = datetime.datetime.now().strftime(\"%Y_%m_%d-%H_%M_%S\")\n",
    "    file = open(f'{output_path}{str(logtime)}/AIAgent_{model_name}_{iter}.md', 'w')\n",
    "    file.write(\"Date: \" + logtime +\"\\n\\n\")\n",
    "    file.write(\"Retriever settings: retriever\" + chosen_emb_model + \", k=\" + str(numb_ret) +\"\\n\\n\")\n",
    "    file.write(\"Model used to infer: \" + model_name +\"\\n\\n\")\n",
    "    file.write(\"Feature: \" + feature + \"\\n\\n\")\n",
    "    file.write(\"Prompt to score the relevance of retrieved documents: \" + ret_system_prompt + \"\\n\\n\")\n",
    "    file.write(\"Prompt to Generate TCs: \" + template + \"\\n\\n\")\n",
    "    file.write(\"================================================\\n\\n\")\n",
    "    file.write('# FILTERED RETRIEVED INFORMATION FROM VECTOR STORE \\n\\n')\n",
    "    for image in retrieved_info[\"images\"]:\n",
    "        file.write(image + '\\n\\n')\n",
    "    for text in retrieved_info[\"texts\"]:\n",
    "        file.write(text+'\\n\\n')\n",
    "    file.write(\"================================================\\n\\n\")\n",
    "    file.write(\"# GENERATED TEST CASES: \\n\\n\")\n",
    "    file.write(answer)\n",
    "    file.close()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e0ca879",
   "metadata": {},
   "source": [
    "## Test Case Subject Rewriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b66592da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# Prompt\n",
    "system = \"\"\"You a question re-writer that converts an input question to a better version that is optimized \\n \n",
    "     for vectorstore retrieval. Look at the input and try to reason about the underlying semantic intent / meaning.\"\"\"\n",
    "re_write_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\n",
    "            \"human\",\n",
    "            \"Here is the initial question: \\n\\n {question} \\n Formulate an improved question.\",\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "question_rewriter = re_write_prompt | sel_model | StrOutputParser()\n",
    "#Test the questions rewriter outside of the graph:\n",
    "# question = \"Testing \"\n",
    "# question_rewriter.invoke({\"question\": question})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08fe4e92",
   "metadata": {},
   "source": [
    "## Test Case Hallucinator Checker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389e988b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt\n",
    "system = \"\"\"You are a grader assessing whether an LLM generation is grounded in / supported by a set of retrieved documents.\n",
    "     Give a binary score 'yes' or 'no' score to indicate whether the document is grounded in / supported by the set of documents\n",
    "     'No' means that the answer is grounded in / supported by the set of documents.\"\"\"\n",
    "\n",
    "hallucination_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\"human\", \"Set of documents: \\n\\n {documents} \\n\\n LLM generation: {generation}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "hallucination_grader = hallucination_prompt | structured_llm_grader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "101b66c9",
   "metadata": {},
   "source": [
    "# Create Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6688f368",
   "metadata": {},
   "source": [
    "## Graph State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "82fc945e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph.message import add_messages, AnyMessage\n",
    "from typing import Annotated, TypedDict, List\n",
    "\n",
    "class State(TypedDict):\n",
    "    \"\"\"\n",
    "    Represents the state of our graph.\n",
    "\n",
    "    Attributes:\n",
    "        messages: history of all messages passed to the LLM\n",
    "        question: question\n",
    "        generation: LLM generation\n",
    "        documents: list of documents\n",
    "    \"\"\"\n",
    "    messages: Annotated[list[AnyMessage], add_messages]\n",
    "    question: str\n",
    "    new_question: str\n",
    "    generation: str\n",
    "    documents: List[str]\n",
    "    new_documents: List[str]\n",
    "    iter: int\n",
    "\n",
    "memory = MemorySaver()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c82e27ba",
   "metadata": {},
   "source": [
    "## Define Graph Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "27b8c4dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_raw_retrieved_doc(prompt, results, iter):\n",
    "    global numb_ret\n",
    "    global chosen_emb_model\n",
    "    global logtime\n",
    "    model_name = get_current_model(sel_model)\n",
    "    # logtime = datetime.datetime.now().strftime(\"%Y_%m_%d-%H_%M_%S\")\n",
    "    file = open(f'{output_path}{str(logtime)}/AIAgent_{model_name}_rawRetrievedDocs_{iter}.md', 'w')\n",
    "    file.write(\"Date: \" + logtime +\"\\n\\n\")\n",
    "    file.write(\"================================================\\n\\n\")\n",
    "    file.write('# RAW RETRIEVED INFORMATION FROM VECTOR STORE \\n\\n')\n",
    "    file.write(\"Retriever settings: retriever\" + chosen_emb_model + \", k=\" + str(numb_ret) +\"\\n\\n\")\n",
    "    file.write(\"Model used to infer: \" + model_name +\"\\n\\n\")\n",
    "    file.write(\"Prompt: \" + prompt +\"\\n\\n\")\n",
    "    file.write(\"================================================\\n\\n\")\n",
    "    for result in results:\n",
    "        try: #if a doc\n",
    "            file.write(result.metadata[\"source\"] + \" \" + str(result.metadata['start_index']) + \"\\n\\n\")\n",
    "            file.write(result.page_content + \"\\n\\n\")\n",
    "        except: #if an image\n",
    "            file.write(result.metadata[\"source\"] + \"\\n\\n\")\n",
    "    file.close()\n",
    "\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcde138f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve(state):\n",
    "    global numb_ret\n",
    "    \"\"\"\n",
    "    Retrieve documents\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): New key added to state, documents, that contains retrieved documents\n",
    "    \"\"\"\n",
    "    print(\"---RETRIEVE---\")\n",
    "    \n",
    "    iter = state[\"iter\"]\n",
    "\n",
    "    if iter == 0 or iter == None:\n",
    "        iter = 1\n",
    "        question = state[\"question\"]\n",
    "        documents = retriever.invoke(question, k=numb_ret)\n",
    "        print_raw_retrieved_doc(question, documents, str(iter))\n",
    "        return {\"question\": question, \"documents\": documents, \"iter\": iter}\n",
    "    else:\n",
    "        iter = state[\"iter\"] + 1\n",
    "        iter = iter + 1\n",
    "        new_question = state[\"new_question\"]\n",
    "        new_documents = retriever.invoke(new_question, k=numb_ret) \n",
    "        print_raw_retrieved_doc(new_question, new_documents, str(iter))\n",
    "        return {\"new_question\": new_question, \"new_documents\": new_documents, \"iter\": iter}\n",
    "\n",
    "\n",
    "def grade_documents(state):\n",
    "    \"\"\"\n",
    "    Determines whether the retrieved documents are relevant to the question.\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): Updates documents key with only filtered relevant documents\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---CHECK DOCUMENT RELEVANCE TO QUESTION---\")\n",
    "\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "    iter = state[\"iter\"]\n",
    "\n",
    "    if iter > 1:\n",
    "        new_question = state[\"new_question\"]\n",
    "        question = question + \" and \" + new_question\n",
    "        new_documents = state[\"new_documents\"]\n",
    "\n",
    "        #Append only unique new documents to the documents List; Exclude any duplicates\n",
    "        for i in range(len(new_documents)):\n",
    "            if new_documents[i] not in documents:\n",
    "                documents.append(new_documents[i])\n",
    "\n",
    "    # Score each doc\n",
    "    filtered_docs = []\n",
    "    for d in documents:\n",
    "        score = retrieval_grader.invoke({\"question\": question, \"document\": d.page_content})\n",
    "        grade = score.binary_score\n",
    "        if grade == \"yes\":\n",
    "            print(\"---GRADE: DOCUMENT RELEVANT---\")\n",
    "            filtered_docs.append(d)\n",
    "        else:\n",
    "            print(\"---GRADE: DOCUMENT NOT RELEVANT---\")\n",
    "            continue\n",
    "\n",
    "    return {\"question\": question, \"documents\": filtered_docs, \"new_documents\": None}\n",
    "\n",
    "def transform_query(state):\n",
    "    \"\"\"\n",
    "    Transform the query to produce a better question.\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        New key added to state, generation, that contains LLM generation\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---TRANSFORM QUERY---\")\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "\n",
    "    # Re-write question\n",
    "    better_question = question_rewriter.invoke({\"question\": question})\n",
    "    return {\"documents\": documents, \"question\": better_question}\n",
    "\n",
    "def generate(state):\n",
    "    \"\"\"\n",
    "    Generate answer\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): New key added to state, generation, that contains LLM generation\n",
    "    \"\"\"\n",
    "    print(\"---GENERATE---\")\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "    \n",
    "    processed_docs = reshape_results(documents)\n",
    "\n",
    "    # RAG generation\n",
    "    template = template_ex_TC_from_file\n",
    "    prompt = ChatPromptTemplate.from_template(template)\n",
    "    chain = prompt | sel_model\n",
    "    example1 = all_tc_contents[0]\n",
    "    example2 = all_tc_contents[1]\n",
    "    example4 = all_tc_contents[3]\n",
    "    example5 = all_tc_contents[4]\n",
    "    example6 = all_tc_contents[5]\n",
    "    example7 = all_tc_contents[6]\n",
    "    example8 = all_tc_contents[7]\n",
    "    \n",
    "    answer = chain.invoke({\"example1\": example1, \"example2\": example2, \"example3\": example5,\n",
    "                           \"feature\": question, \"context\": processed_docs})\n",
    "\n",
    "    iter = state[\"iter\"]\n",
    "\n",
    "    output_TC(question, processed_docs, answer.pretty_repr(), str(iter))\n",
    "    return {\"documents\": documents, \"question\": question, \"generation\": answer}\n",
    "\n",
    "def hallucination_checker(state):\n",
    "    \"\"\" \n",
    "    Given the Generated Test Case, \n",
    "    Check that the content is grounded in facts.\n",
    "\n",
    "    Args: \n",
    "        state (dict): The current graph state\n",
    "    \n",
    "    Returns:\n",
    "        state (dict): Updates new_question key with key terms of specs that are missing from test case.\n",
    "    \"\"\"\n",
    "    print(\"---EVALUATING TEST CASE CONTENT FOR HALLUCINATIONS---\")\n",
    "    documents = state[\"documents\"]\n",
    "    generation = state[\"generation\"]\n",
    "\n",
    "    score = hallucination_grader.invoke({\"documents\": documents, \"generation\": generation})\n",
    "    grade = score.binary_score\n",
    "    \n",
    "    if grade == \"yes\":\n",
    "        return {\"generation\": \"hallucinations\"}\n",
    "    else:\n",
    "        return {\"generation\": \"no_hallucinations\"}\n",
    "    \n",
    "    \n",
    "\n",
    "def human_feedback(state):\n",
    "    \"\"\"\n",
    "    Given the Generated Test Case, \n",
    "    Ask the User if there is any missing context that shoud be retrieved from the vectorstore\n",
    "\n",
    "    Args: \n",
    "        state (dict): The current graph state\n",
    "    \n",
    "    Returns:\n",
    "        state (dict): Updates new_question key with key terms of specs that are missing from test case.\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---EVALUATING TEST CASE CONTENT FOR COMPLETENESS---\")\n",
    "    \n",
    "\n",
    "    missing_info = input(\"Enter any information that is missing as input to the test case that was generated. Or type 'None':\")\n",
    "    print(\"Human said the missing feedback is: \", missing_info)\n",
    "    return{\"new_question\": missing_info}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "680224ca",
   "metadata": {},
   "source": [
    "## Define Functions of Graph Edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "1053a5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decide_to_generate(state):\n",
    "    \"\"\"\n",
    "    Determines whether to generate an answer, or re-generate a question.\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        str: Binary decision for next node to call\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---ASSESS GRADED DOCUMENTS---\")\n",
    "    state[\"question\"]\n",
    "    filtered_documents = state[\"documents\"]\n",
    "\n",
    "    if not filtered_documents:\n",
    "        # If No documents are related to the feature, then we will rephrase the feature to generate test cases on. \n",
    "        print(\"---DECISION: ALL DOCUMENTS ARE NOT RELEVANT TO QUESTION, TRANSFORM QUERY---\")\n",
    "        return \"transform_query\"\n",
    "    else:\n",
    "        # We have relevant documents, so generate answer\n",
    "        print(\"---DECISION: GENERATE---\")\n",
    "        return \"generate\"\n",
    "    \n",
    "def decide_if_hallucinated(state):\n",
    "    generated_tc = state[\"generation\"]\n",
    "    if generated_tc == \"no_hallucinations\":\n",
    "        print(\"---DECISION: NO HALLUCINATIONS---\")\n",
    "        return \"human_feedback\"\n",
    "    else:\n",
    "        print(\"---DECISION: HALLUCINATIONS ARE PRESENT, REGENERATE A RESPONSE\")\n",
    "        return \"generate\"\n",
    "\n",
    "def decide_to_approve(state):\n",
    "    new_query = state[\"new_question\"]\n",
    "    \n",
    "    if new_query != \"None\":\n",
    "        print(\"---RETRIEVE MISSING SPECS FROM DATABASE---\")\n",
    "        return \"retrieve\"\n",
    "    else:\n",
    "        print(\"--END--\")\n",
    "        return \"end\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36efcf0f",
   "metadata": {},
   "source": [
    "## Build Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "a7bb34fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "from IPython.display import Image, display\n",
    "\n",
    "workflow = StateGraph(State)\n",
    "\n",
    "# Define the nodes\n",
    "workflow.add_node(\"retrieve\", retrieve)  # retrieve\n",
    "workflow.add_node(\"grade_documents\", grade_documents)  # grade documents\n",
    "workflow.add_node(\"generate\", generate)  # generate\n",
    "workflow.add_node(\"transform_query\", transform_query)  # transform_query\n",
    "workflow.add_node(\"human_feedback\", human_feedback) #review the TC generated and ensure there was no missing inputs\n",
    "# workflow.add_node(\"hallucination_checker\", hallucination_checker)\n",
    "\n",
    "# Define the edges\n",
    "workflow.add_edge(START, \"retrieve\")\n",
    "workflow.add_edge(\"retrieve\", \"grade_documents\")\n",
    "workflow.add_conditional_edges(\n",
    "    \"grade_documents\",\n",
    "    decide_to_generate,\n",
    "    {\n",
    "        \"transform_query\": \"transform_query\",\n",
    "        \"generate\": \"generate\"\n",
    "    }\n",
    ")\n",
    "workflow.add_edge(\"transform_query\", \"retrieve\")\n",
    "workflow.add_edge(\"generate\", \"human_feedback\")\n",
    "# workflow.add_conditional_edges(\n",
    "#     \"hallucination_checker\",\n",
    "#     decide_if_hallucinated,\n",
    "#     {\n",
    "#         \"human_feedback\": \"human_feedback\",\n",
    "#         \"generate\": \"generate\",\n",
    "#     }\n",
    "# )\n",
    "workflow.add_conditional_edges(\n",
    "    \"human_feedback\", \n",
    "    decide_to_approve,\n",
    "    {\n",
    "        \"retrieve\": \"retrieve\",\n",
    "        \"end\": END,\n",
    "    }\n",
    ")\n",
    "\n",
    "# Compile/Build the graph\n",
    "graph = workflow.compile(checkpointer = memory)\n",
    "\n",
    "#Print the structure of the Graph\n",
    "display(Image(graph.get_graph(xray=True).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7cb022c",
   "metadata": {},
   "source": [
    "# Execute Test Case Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d6bcdd4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder 'outputs/2025_07_06-23_27_40' created successfully.\n",
      "---RETRIEVE---\n",
      "***** Result from Agent:  retrieve\n",
      "pass\n",
      "---CHECK DOCUMENT RELEVANCE TO QUESTION---\n",
      "---GRADE: DOCUMENT RELEVANT---\n",
      "---GRADE: DOCUMENT RELEVANT---\n",
      "---GRADE: DOCUMENT RELEVANT---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---GRADE: DOCUMENT RELEVANT---\n",
      "---GRADE: DOCUMENT RELEVANT---\n",
      "---GRADE: DOCUMENT RELEVANT---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---GRADE: DOCUMENT RELEVANT---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---ASSESS GRADED DOCUMENTS---\n",
      "---DECISION: GENERATE---\n",
      "***** Result from Agent:  grade_documents\n",
      "pass\n",
      "---GENERATE---\n",
      "***** Result from Agent:  generate\n",
      "pass\n",
      "---EVALUATING TEST CASE CONTENT FOR COMPLETENESS---\n",
      "Human said the missing feedback is:  cancel registration\n",
      "---RETRIEVE MISSING SPECS FROM DATABASE---\n",
      "***** Result from Agent:  human_feedback\n",
      "pass\n",
      "---RETRIEVE---\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'new_question' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[75]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# test_case_subject = \"Intra-operative Import Subpanel's Bead Detection Algorithm Failure and execution of all available pathways on the Object Detection Error Pop-up\"\u001b[39;00m\n\u001b[32m     12\u001b[39m test_case_subject = \u001b[33m\"\u001b[39m\u001b[33mAll features related to the \u001b[39m\u001b[33m'\u001b[39m\u001b[33mLocate Markers Breadcrumb Step\u001b[39m\u001b[33m'\u001b[39m\u001b[33m and \u001b[39m\u001b[33m'\u001b[39m\u001b[33mPoint to Markers Subpanel\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m \u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mquestion\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_case_subject\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43miter\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mthread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mupdates\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m***** Result from Agent: \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Projects/ZB_TC_Brain_Generator/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py:2436\u001b[39m, in \u001b[36mPregel.stream\u001b[39m\u001b[34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, checkpoint_during, debug, subgraphs)\u001b[39m\n\u001b[32m   2434\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m loop.match_cached_writes():\n\u001b[32m   2435\u001b[39m             loop.output_writes(task.id, task.writes, cached=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m2436\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrunner\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2437\u001b[39m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrites\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2438\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstep_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2439\u001b[39m \u001b[43m            \u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2440\u001b[39m \u001b[43m            \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43maccept_push\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2441\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   2442\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# emit output\u001b[39;49;00m\n\u001b[32m   2443\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01myield from\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2444\u001b[39m \u001b[38;5;66;03m# emit output\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[71]\u001b[39m\u001b[32m, line 24\u001b[39m, in \u001b[36mretrieve\u001b[39m\u001b[34m(state)\u001b[39m\n\u001b[32m     22\u001b[39m \u001b[38;5;28miter\u001b[39m = state[\u001b[33m\"\u001b[39m\u001b[33miter\u001b[39m\u001b[33m\"\u001b[39m] + \u001b[32m1\u001b[39m\n\u001b[32m     23\u001b[39m \u001b[38;5;28miter\u001b[39m = \u001b[38;5;28miter\u001b[39m + \u001b[32m1\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m new_documents = retriever.invoke(\u001b[43mnew_question\u001b[49m, k=numb_ret) \n\u001b[32m     25\u001b[39m print_raw_retrieved_doc(new_question, new_documents, \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28miter\u001b[39m))\n\u001b[32m     26\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[33m\"\u001b[39m\u001b[33mnew_question\u001b[39m\u001b[33m\"\u001b[39m: new_question, \u001b[33m\"\u001b[39m\u001b[33mnew_documents\u001b[39m\u001b[33m\"\u001b[39m: new_documents, \u001b[33m\"\u001b[39m\u001b[33miter\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28miter\u001b[39m}\n",
      "\u001b[31mNameError\u001b[39m: name 'new_question' is not defined",
      "During task with name 'retrieve' and id 'cddbf4ce-6bef-f41e-0c6e-e99f9a305b17'"
     ]
    }
   ],
   "source": [
    "thread = {\"configurable\": {\"thread_id\": 1}} #used to store all the checkpoints into memory\n",
    "logtime = datetime.datetime.now().strftime(\"%Y_%m_%d-%H_%M_%S\")\n",
    "folder_path = \"outputs/\" + logtime\n",
    "if not os.path.exists(folder_path):\n",
    "    # If it doesn't exist, create it\n",
    "    os.makedirs(folder_path)\n",
    "    print(f\"Folder '{folder_path}' created successfully.\")\n",
    "else:\n",
    "    print(f\"Folder '{folder_path}' already exists.\")\n",
    "    \n",
    "# test_case_subject = \"Intra-operative Import Subpanel's Bead Detection Algorithm Failure and execution of all available pathways on the Object Detection Error Pop-up\"\n",
    "test_case_subject = \"All features related to the 'Locate Markers Breadcrumb Step' and 'Point to Markers Subpanel'\"\n",
    "\n",
    "for output in graph.stream({\"question\": test_case_subject, \"iter\": 0}, config=thread, stream_mode=\"updates\"):\n",
    "    for key, value in output.items():\n",
    "        print(\"***** Result from Agent: \",key)\n",
    "        \n",
    "        try:\n",
    "            last_message = next(iter(output.values()))[\"messages\"][-1]\n",
    "            last_message.pretty_print()\n",
    "        except:\n",
    "            print(\"pass\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e984588",
   "metadata": {},
   "source": [
    "# Conclusions from Experiments:\n",
    "\n",
    "**Retrieval of documents from VectorStore:**\n",
    "\n",
    "***Observation:*** We use the same embedding model to retrieve relevant documents/images from the database; Despite this, we are given different combos of doc chunks to evaluate each time that the retriever is invoked. (more precisely, we are given the same top 2 docs, but after the first 2, we get a whole bunch of different non-sense.)\n",
    "\n",
    "***TODO:*** Look into how to make the retrieval of relevant documents more consistent. (Not a Strong Priority)\n",
    "- Option 1: Add Human in the loop (to identify if any details are missing)***\n",
    "- Option 2: Get the LLM to ask Clarifying Questions \n",
    "- Alternative: Change this into a manual input to the rest of the system.\n",
    "\n",
    "---\n",
    "\n",
    "**Relevancy Grader:**\n",
    "- system1 prompt > system3 > system2 (from less stringent to most stringent)\n",
    "- Using the \"system1\" prompt, Llama scored more of the SWRS as relevant > Gemma > Granite\n",
    "- Next Steps: Make the Relevancy Grader less stringent \n",
    "    - make vectorstore retrieve all keywords from requirements that were graded as relevant (make the transform query method re-ping the vectorstore for reqs. containing the keywords from the relevant reqs. and set a max iteration to 3?)\n",
    "\n",
    "----\n",
    "\n",
    "**Generate Test Cases:** \n",
    "- See conclusions in \"main_RAG.ipynb\" for why we chose the Llama model as the best model for test case creation. \n",
    "- The Generated Test cases show that the LLM has a tendency to hallucinate quite a lot. To reduce Hallucinations, we can try some methods:\n",
    "    - Chain of thought. \n",
    "    - Provide more context and increase the context window of the LLM \n",
    "\n",
    "---\n",
    "\n",
    "**Evaluate Test Cases vs. Input Contextual Document Database:**\n",
    "- Right now the generated test cases adhere to the retrieved Specs that are fed to it; however, there are some weaknesses to this system:\n",
    "    1. many related specs involving convoluted navigation scenarios have context holes for the preconditions \n",
    "        - Possible Solutions:\n",
    "            - Add Human in the Loop to edit the content of the test case (alternative is to just do this before uploading to CB)\n",
    "            - Feed a separate node the last line of the preconditions steps, and get the node to fetch all content in the SWRS to figure out how to get from the launch page to that panel.\n",
    "                \n",
    "    2. Many steps are missing the in-between steps in order to get from one spec to verify to the next step to verify. For example, any situation where you need to go all the way to reg. valid, reject the registration, and return to perform XXXX action.\n",
    "        - Possible Solutions:\n",
    "            - Implement chain of thought: Add \"Let's think step by step\" to the prompt asking it to identify the SWRS that explain how the user navigates from one step to the next. \n",
    "            - Allow the Test cases to be generated such that there is one test case per swrs, so if a step is missing, it means that you are missing a SwRS. \n",
    "            - Add a Human in the Loop to retrieve more requrements related to a new query containing key terms for specs that might be missing to complete the execution steps considering all of the context contained in the entire specs document. (IMPLEMENTED)\n",
    "        \n",
    "\n",
    "If you want to get test cases to be generated for an entire section of the application, we need a way to be able to group SwRS together to feed to the generator (one set of inputs of SwRs per Generator) to Parallelize the generation of Test Cases to Optimize for time. \n",
    "\n",
    "Feed a list of SwRS, and track which SwRS, if any the AI_Agent has skipped writing a TC for:\n",
    "- parse the list of inputed SWRS and compare it with the outputted TCs .md file. \n",
    "\n",
    "# TO EVALUATE:\n",
    "- Check if the generator gives you both positive and negative test cases; scnearios to test: importing images and different modalities; "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0307ea0b",
   "metadata": {},
   "source": [
    "# Adding Chain of Thought to Evaluate the appropriateness of the test case steps returned to the user. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bfd4fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tc_to_eval_path = \"./outputs/2025_07_01-22_23_53/AIAgent_llama3.1-8b_1.md\"\n",
    "\n",
    "#Break up the Test cases into separate .md files\n",
    "\n",
    "\n",
    "def eval_test_case():\n",
    "    '''\n",
    "    For each .md file:\n",
    "        Execute the first step = Send the preconditions and action to the vector store to retrieve all similar content. The LLM will then infer from the retrieved docs what should be displayed on the screen. \n",
    "        Compare what the LLM spat out with the expected result in the .md file. \n",
    "            If it passes, then keep the context of the history of the chat and add the next step. Feed all of this information to the LLM so that it figures out what should be displayed on the screen.\n",
    "            If it fails, then send both outputs to the human to evaluate what to keep and what to discard. \n",
    "        Compare what the LLM  spat out with the expected result in the .md file. \n",
    "    '''\n",
    "\n",
    "    system = \"\"\"Let's think step by step.\n",
    "\n",
    "            \"\"\"\n",
    "    \n",
    "    print(\"---Finished Evaluating Test Case---\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
